<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[毛無しさん@キレートレモン]]></title>
  <link href="http://ojima-h.github.com/atom.xml" rel="self"/>
  <link href="http://ojima-h.github.com/"/>
  <updated>2013-08-30T16:51:21+09:00</updated>
  <id>http://ojima-h.github.com/</id>
  <author>
    <name><![CDATA[ojima_h]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hive クエリを最適化する]]></title>
    <link href="http://ojima-h.github.com/blog/2013/08/30/hive-optimization/"/>
    <updated>2013-08-30T11:23:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2013/08/30/hive-optimization</id>
    <content type="html"><![CDATA[<ul>
<li><a href="http://www.amazon.co.jp/Hadoop-Tom-White/dp/487311439X">Hadoop本</a></li>
<li><a href="http://www.amazon.co.jp/Hadoop-Hacks-%E2%80%95%E3%83%97%E3%83%AD%E3%83%95%E3%82%A7%E3%83%83%E3%82%B7%E3%83%A7%E3%83%8A%E3%83%AB%E3%81%8C%E4%BD%BF%E3%81%86%E5%AE%9F%E8%B7%B5%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF-%E4%B8%AD%E9%87%8E-%E7%8C%9B/dp/4873115469">HADOOP HACKS</a></li>
</ul>


<p>を参考に、HiveQL が どんな Map/Reduce タスクに展開されるのかを想像しつつ(ソースは読んでないのであくまで想像)、
効率の良い Hiveクエリの書き方を考えてみる。</p>

<h2>まずは、普通のクエリ</h2>

<pre><code>SELECT * FROM movie
</code></pre>

<p>は、どんな Map/Reduce タスクに変換されるんでしょうか？</p>

<p>hive で</p>

<pre><code>&gt; EXPLAIN SELECT * FROM movie;
</code></pre>

<p>とやってみると、</p>

<pre><code>ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME movie))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
</code></pre>

<p>と返っくる。
たぶん、<code>Stage-0</code> は「ただ吐き出す」ていうタスクなんだろう。</p>

<p><code>SELECT * FROM movie LIMIT 10</code> と比較してみる:</p>

<pre><code>&gt; EXPLAIN SELECT * FROM movie LIMIT 10;

ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME all_member))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))

STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: 10
</code></pre>

<p><code>Stage-0</code> は、<code>LIMIT</code> の面倒だけ見ている気がする。</p>

<h2>SELECT WHERE してみる</h2>

<pre><code>&gt; EXPLAIN SELECT id FROM movie WHERE year = 2000 LIMIT 10;

ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME movie))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL id))) (TOK_WHERE (= (TOK_TABLE_OR_COL year) 2000))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&gt; Map Operator Tree:
        movie 
          TableScan
            alias: movie
            Filter Operator
              predicate:
                  expr: (year = 2000)
                  type: boolean
              Select Operator
                expressions:
                      expr: id
                      type: int
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1
</code></pre>

<p>たぶん mapper はこんなイメージかな&#8230;？</p>

<pre><code>public void map(Integer key, Text row, OutputCollector&lt;Integer, Text&gt; output, ...) {
    Integer id = row.getId();
    Integer year = row.getYear();

    if (year == 2000) {
        output.collect(key, new Writable(id));
    }
}
</code></pre>

<h2>GROUP BY してみる</h2>

<pre><code>&gt; EXPLAIN SELECT year, count(*) FROM movie GROUP BY year;

ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME movie))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL year)) (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_GROUPBY (TOK_TABLE_OR_COL year))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&gt; Map Operator Tree:
        movie 
          TableScan
            alias: movie
            Select Operator
              expressions:
                    expr: year
                    type: string
              outputColumnNames: year
              Group By Operator
                aggregations:
                      expr: count()
                bucketGroup: false
                keys:
                      expr: year
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col0
                  type: string
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1
</code></pre>

<p>Map Operator Tree の中に Reduce Output Operator があるのは、map task と reduce task 間のデータ転送量を小さくするために
map task 側で集約関数(combiner)を呼ぶためだと思われる。</p>

<p>たぶん mapper はこんなイメージ&#8230;</p>

<pre><code>public void map(Integer key, Text row, OutputCollector&lt;Integer, Text&gt; output, ...) {
    Integer year = row.getYear();

    output.collect(year, new Writable(key));
}
</code></pre>

<p>reducer (と combiner) は多分こんな感じ&#8230;</p>

<pre><code>publick void reduce(Text year, Iterator&lt;Text&gt; values, OutputCollector&lt;Text,BigInt&gt; output, ...) {
    BigInt count = values.count();

    output.collect(&lt;何かしらのKEY&gt;, new Writable(new Row(year, count)));
}
</code></pre>

<h2>問題は JOIN</h2>

<pre><code>&gt; EXPLAIN SELECT a.id, b.rating FROM movie a JOIN score b on a.id = b.movie_id

ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME movie) a) (TOK_TABREF (TOK_TABNAME score) b) (= (. (TOK_TABLE_OR_COL a) id) (. (TOK_TABLE_OR_COL b) movie_id)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) id)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) rating)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&gt; Map Operator Tree:
        a 
          TableScan
            alias: a
            Reduce Output Operator
              key expressions:
                    expr: id
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: id
                    type: int
              tag: 0
              value expressions:
                    expr: id
                    type: int
        b 
          TableScan
            alias: b
            Reduce Output Operator
              key expressions:
                    expr: movie_id
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: movie_id
                    type: int
              tag: 1
              value expressions:
                    expr: rating
                    type: int
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0}
            1 {VALUE._col1}
          handleSkewJoin: false
          outputColumnNames: _col0, _col3
          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col3
                  type: int
            outputColumnNames: _col0, _col1
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1
</code></pre>

<p>処理の流れはたぶんこんな感じ:</p>

<ol>
<li><p><strong>MAPPER</strong></p>

<p><code>movie</code> テーブルと <code>score</code> テーブルから必要なカラムを抜きだす。</p></li>
<li><p><strong>REDUCER</strong></p>

<p>mapper からデータをコピーする。このとき、同じ結合キー (movie.id と score.movie_id) を持つデータは
同じ reduce task にコピーされる。
で、結合して、指定されたカラムを返す。</p></li>
</ol>


<h2>MAPJOIN してみる</h2>

<p>HADOOP HACKS とかに、マップサイドジョンが紹介されていたので、試してみる。</p>

<pre><code>&gt; EXPLAIN SELECT /*+ MAPJOIN(a) */ id, rating FROM movie a JOIN score b ON a.id = b.movie_id;

ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME movie) a) (TOK_TABREF (TOK_TABNAME score) b) (= (. (TOK_TABLE_OR_CO
L a) id) (. (TOK_TABLE_OR_COL b) movie_id)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TO
K_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR (TOK_TABLE_OR_COL id)) (TOK_SELEXPR (TOK_TABLE_OR_COL rating)))))

STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-1 depends on stages: Stage-3
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-3
    Map Reduce Local Work
      Alias -&gt; Map Local Tables:
        a 
          Fetch Operator
            limit: -1
      Alias -&gt; Map Local Operator Tree:
        a 
          TableScan
            alias: a
            HashTable Sink Operator
              condition expressions:
                0 {id}
                1 {rating}
              handleSkewJoin: false
              keys:
                0 [Column[id]]
                1 [Column[movie_id]]
              Position of Big Table: 1

  Stage: Stage-1
    Map Reduce
      Alias -&gt; Map Operator Tree:
        b 
          TableScan
            alias: b
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              condition expressions:
                0 {id}
                1 {rating}
              handleSkewJoin: false
              keys:
                0 [Column[id]]
                1 [Column[movie_id]]
              outputColumnNames: _col0, _col3
              Position of Big Table: 1
              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col3
                      type: int
                outputColumnNames: _col0, _col3
                Select Operator
                  expressions:
                        expr: _col0
                        type: int
                        expr: _col3
                        type: int
                  outputColumnNames: _col0, _col1
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
</code></pre>

<p>たしかに reduce task がなくなっている。</p>

<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization</a> には、MAPJOIN の説明が以下のようにされている。</p>

<blockquote><p>  MAPJOINs are processed by loading the smaller table into an in-memory hash map and matching keys with the larger table as they are streamed through. The prior implementation has this division of labor:</p>

<ul>
<li>  Local work:

<ul>
<li>  read records via standard table scan (including filters and projections) from source on local machine</li>
<li>  build hashtable in memory</li>
<li>  write hashtable to local disk</li>
<li>  upload hashtable to dfs</li>
<li>  add hashtable to distributed cache</li>
</ul>
</li>
<li>  Map task

<ul>
<li>  read hashtable from local disk (distributed cache) into memory</li>
<li>  match records&#8217; keys against hashtable</li>
<li>  combine matches and write to output</li>
</ul>
</li>
<li>  No reduce task</li>
</ul>
</blockquote>

<p>Stage-3 で、<code>movie</code> テーブルを読み込んで hashtable を構築しているようだ。
で、Stage-1 の map task で、この hashtable を使いながら <code>socre</code> テーブルを読み込んでいくのだろう。</p>

<h2>Map Side Join についてもう少し考えてみる</h2>

<p>Hadoop本の中で、「map側結合」が紹介されていた。(p.254 8.3.1 map側結合)
ここで説明されている map 側結合と、Hive の MAPJOIN はどうも違うようだ。</p>

<p>Hadoop本の map 側結合が Hive クエリ実行時に行なわれることはないのだろうか？
Join 対象になる2つのテーブル (もしくは、サブクエリの結果) のデータが、
結合キーごとに同じデータノードに入っている状況。</p>

<p>うん。。</p>

<p>思いつかない。</p>

<h2>その他の JOIN の最適化方法</h2>

<ul>
<li><a href="https://cwiki.apache.org/confluence/download/attachments/27362054/Hive+Summit+2011-join.pdf?version=1&amp;modificationDate=1310001042000">https://cwiki.apache.org/confluence/download/attachments/27362054/Hive+Summit+2011-join.pdf?version=1&amp;modificationDate=1310001042000</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Skewed+Join+Optimization">https://cwiki.apache.org/confluence/display/Hive/Skewed+Join+Optimization</a></li>
</ul>


<p>とかもあるみたい。</p>

<h3>Bucket Map Join</h3>

<p>Join 対象のテーブルが bucketize されている場合、構築された hashtable を bucket key に基づいて、必要な map task にだけ配布するっぽい。</p>

<h3>Sort Merge Map Join</h3>

<p>Join 対象のテーブルが bucketize されていて、しかも sort されている場合、もっと早くなるみたい。</p>

<p>でも、sort するのが大変。</p>

<h3>Skewed Join</h3>

<p>よく分からない。</p>

<h2>その他、思ったこと</h2>

<ul>
<li><p>MAPJOIN はテーブル1つをまるごとメモリに載せないといけないので、
せいぜい数十メガから数百メガのテーブルじゃないと辛そう。
サブクエリの中で十分絞り込んだ後 JOIN するのが実用的かも。</p></li>
<li><p>Bucket Map Join は、既存のHiveテーブルに対して、後から bucketize するのは大変そう。
集計用の中間テーブルを作ることがあったら、検討してみるといいかも。</p></li>
<li><p>HADOOP HACKS の中で、UDF (User Define Fucntion) や UDAF (User Define Aggregate Function) の作り方が載っていた。
この辺をもっとサクサク使えるようになるとはかどりそうな気がした。
むしろ、使わないともったいない。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop のチューニングに関してまとめ]]></title>
    <link href="http://ojima-h.github.com/blog/2013/08/29/hadoop-tuning/"/>
    <updated>2013-08-29T16:06:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2013/08/29/hadoop-tuning</id>
    <content type="html"><![CDATA[<p>1効率の良い HiveQL を書くときに気をつけるべきことをまとめてみる。</p>

<p><em>以下に書いたことは、ほとんど全部自分なりの解釈なので、間違いが多々あると思います</em></p>

<p>Hadoop一般のチューニングに関しては、ここを参考にした。</p>

<p><a href="http://www.cloudera.co.jp/jpevents/cloudera-world-tokyo/pdf/A3_Hadoop%E3%81%AE%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E8%A8%AD%E8%A8%88_%E9%81%8B%E7%94%A8%E3%81%AE%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88.pdf">http://www.cloudera.co.jp/jpevents/cloudera-world-tokyo/pdf/A3_Hadoop%E3%81%AE%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E8%A8%AD%E8%A8%88_%E9%81%8B%E7%94%A8%E3%81%AE%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88.pdf</a></p>

<p><a href="http://www.amazon.co.jp/Hadoop-Tom-White/dp/487311439X">Hadoop本</a> を参考に、この資料の補足してみた↓</p>

<h2>ラック内ネットワークとラック間ネットワークは何が違うのか？</h2>

<p><em>(p.69 「ネットワークトポロジとHadoop」 / p.267 9.1.1 ネットワークトポロジ)</em></p>

<p>Hadoop は、データを読み書きする際にネットワークのトポロジやネットワーク構成を勘案しながら動作する。
読み込みを行う際には、クライアントになるべく <em>近い</em> ノードから読み込むように調整するし、
書き込みを行う際には、データのレプリカが近い場所に集中してしまわないように調整する。</p>

<p>2つのノード間のデータ転送速度が早いほど、この2つのノードが <em>近い</em> と見做される。
Hadoop は、ノード間の距離をネットワーク構成から算出している。
つまり、「同じラックにある2つのノードは互いに近い = 転送速度が早い」ものとして処理を進める。</p>

<p>そのため、同じラック内にあるのに実際には転送速度が遅い、ということになると、
Hadoop が効率良くデータを処理することができなくなってしまう。</p>

<h2>スレーブノードでは、なぜ RAID0 を組んではダメなのか？</h2>

<p><em>(p.266 「RAIDを使わないのはなぜ？」)</em></p>

<ul>
<li>HDFSはノード間の複製によって冗長性を持つので、RAIDで冗長性を提供してもらう必要がない。(←弱い)</li>
<li>RAID0 でデータロストが発生した事例あり</li>
</ul>


<h2>マスターノードでRaidを組まないと何が起きるのか？</h2>

<p>マスターノード (= ネームノード) は、クラスタ上のどのノードにどのファイルのデータが保存されているかを管理している。
マスターノードのデータが壊れると、HDFSからファイルデータを読み取ることができなくなってしまう。</p>

<p>そのため、マスターノードは信頼性を確保しておく必要がある。</p>

<h2>マスターとスレーブで、求められるCPU性能が違うのはなぜ？</h2>

<p>実際に計算するのはスレーブノード。
マスターノードは、クライアントの要求を受けて適切なスレーブノードに指令を出すのが仕事。
だから、マスターノードはたいしてCPU性能を必要としない。</p>

<h2>ECCとはなんぞ？</h2>

<p><a href="http://e-words.jp/w/ECCE383A1E383A2E383AA.html">Error Check and Correct memory</a></p>

<blockquote><p>メモリに誤った値が記録されていることを検出し、正しい値に訂正することができるメモリモジュール。</p></blockquote>

<h2>なんで圧縮したら「速度」があがるの？</h2>

<p>マップタスクからの出力は一時的にディスクに保存される。
レデュースタスクからの出力もディスクに保存される。</p>

<p>一般的には、Hadoopはかなり大きなデータを扱うので、出力結果を圧縮しないままディスクに書き込む時間よりも、
(圧縮する時間 + 圧縮データをディスクに書き込む時間) の方が短くなる。
読み込む時も同様に、非圧縮のデータを読み出す時間よりも、(圧縮されたデータを読み出す時間 + 解凍する時間) の方が短かくなる。</p>

<h2>ブロック数(サイズ)とヒープサイズの関係は？ (16枚目)</h2>

<p>ブロック数が小さい = ブロックサイズが大きい = ディスクから1回に読み込むデータのサイズが大きい = ディスクへのアクセスが減る</p>

<p>ヒープサイズが大きい = 計算結果を沢山メモリに置いておける = 計算結果をディスクに書き出すことが減る = ディスクへのアクセスが減る</p>

<p>⇒ <strong>速い</strong></p>

<h2>フェデレーション？て何？</h2>

<p><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/Federation.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/Federation.html</a></p>

<blockquote><p>The prior HDFS architecture allows only a single namespace for the entire cluster. A single Namenode manages this namespace. HDFS Federation addresses limitation of the prior architecture by adding support multiple Namenodes/namespaces to HDFS file system.</p>

<p>In order to scale the name service horizontally, federation uses multiple independent Namenodes/namespaces. The Namenodes are federated, that is, the Namenodes are independent and don’t require coordination with each other. The datanodes are used as common storage for blocks by all the Namenodes. Each datanode registers with all the Namenodes in the cluster. Datanodes send periodic heartbeats and block reports and handles commands from the Namenodes.</p></blockquote>

<p>ネームノードの性能をスケールさせるために、HDFSファイル空間を2つに分けてしまって2つのネームノードでそれぞれ担当しよう、という話のようだ。</p>

<p>ネームノードの冗長化とはまた別の話なのかな？</p>

<h2>「ディスクのマウントポイントごとに別々のディレクトリをカンマ区切りで指定すること」てどういう意味？(21枚目)</h2>

<p>1つのデータノードのストレージはいくつかのディスクで構成されている。
ディスクが複数あってそれぞれにデータが分散して保存されているから、
データノードは処理を並列して行うことができる。</p>

<p>で、データノードは <code>dfs.datanode.data.dir</code> に指定されたディレクトリに対してラウンドロビンで書き込んでいくから、
<code>dfs.datanode.data.dir</code> には、複数あるディスクのそれぞれのマウントポイントを指定しないとダメだよ、ということ。</p>

<p>ちなみに、JBOD っていうのは、<a href="http://ja.wikipedia.org/wiki/JBOD">http://ja.wikipedia.org/wiki/JBOD</a> 参照。</p>

<h2>「タクク数 > ディスク数」てどういう状態？(25枚目)</h2>

<p>それぞれのタスクは、(普通は)ディスクからデータを読みとってから計算をはじめる。
「タクク数 > ディスク数」になってしまうと、並行してディスクアクセスを行なえるスレッド数(プロセス数？)の限界を越えて、
タスクノードがディスクアクセスを要求してくることになる。</p>

<p>で、ディスクアクセスが詰まってしまう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ActiveRecord #1]]></title>
    <link href="http://ojima-h.github.com/blog/2012/10/26/activerecord-number-1/"/>
    <updated>2012-10-26T08:40:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/10/26/activerecord-number-1</id>
    <content type="html"><![CDATA[<p>前回 Arel が SQL を構築するところを読んだので、次は ActiveRecord がデータベースを操作するときに、どのタイミングで SQL を構築しているのかを見たいと思います。</p>

<p>このサンプルで、<code>User.where(...)</code>の時点でSQLが発行されてしまうと、その後に続く<code>.limit(10)</code>が反映されないはずじゃないか、というのか今回の疑問です。</p>

<hr />

<p>まず、<code>#where</code>の場所を探します。</p>

<p><code>ActiveRecord</code>はざっくりこんなかんじになっています↓</p>

<h2>Module#delegate</h2>

<p>ref. <a href="http://api.rubyonrails.org/classes/Module.html#method-i-delegate">http://api.rubyonrails.org/classes/Module.html#method-i-delegate</a></p>

<p><code>delegate</code> は、<code>active_support</code>の中で<code>Module#delegate</code>として定義されています。</p>

<p>上の例では、<code>Hoge#method</code>の呼び出すと、<code>Hoge#target</code>が返すオブジェクトの<code>method</code>メソッドが呼ばれます。</p>

<h2><code>Concern#included</code></h2>

<p><code>included</code>メソッドも同じく<code>active_support</code>で定義されており、
そのモジュールがincludeされた時に、ブロックの中身が実行されます。</p>

<hr />

<p>というわけで、<code>Relation#where</code>が呼び出されることが分かります。</p>

<h2><code>Relation#where</code></h2>

<p><code>build_where</code>の中身を追っていくと、
<code>PredicateBuilder#build_from_hash</code>内の以下のコードが実行されることが分かります。</p>

<p>上のコード内の<code>default_table</code>には
<code>Arel::Table</code>のインスタンスが入っています。</p>

<p>とういわけで、<code>User.where(:name =&gt; "John")</code>を実行したとき、
<code>Relation#build_where</code>の結果は<code>[table[:name].eq("John")]</code>となります。
これが<code>Relation#where_values</code>に格納されます。</p>

<p>以上で、<code>ActiveRecord::Base#where</code>の呼び出しは終わりです。</p>

<p>まとめると、<code>ActiveRecord::Base#where</code>を呼び出すと、<code>Relation</code>クラスのインスタンスが返されます。
その中には<code>table[column].eq(value)</code>たちが入った配列が格納されています。</p>

<h2><code>Relation#limit</code></h2>

<p><code>Relation#limit</code>も同じかんじです。</p>

<h2>で、いつSQL？</h2>

<p>さて、<code>User.where(..).limit(10)</code>の結果、<code>Relation</code>クラスのインスタンスが返ってくることは分かりましたが、
これがいつSQLに変換され、データベースに向けて投げられるんでしょうか？</p>

<p><code>where</code>の検索結果が必要になるのはどんな時でしょうか？</p>

<p>大抵の場合、検索結果から個々の<code>User</code>クラスのインスタンスを取り出すときかと思います。
このとき、検索結果に対しては Array としてアクセスすると思います。</p>

<p>というわけで、<code>Relation#to_a</code>について見てみました。</p>

<p><code>scope</code>とか<code>eager_loading</code>とかよく分からないことは置いておいて、デバッガで追いかけると、
<code>@klass.find_by_sql(arel, @bind_values)</code>が実行されることが分かります。</p>

<p>ということは、<code>arel</code>の値が問題になりそうです。</p>

<p>こんなかんじになってました。
この<code>build_arel</code>で、<code>where</code>とか<code>limit</code>に渡された引数たちを、
まとめて<code>Arel</code>のオブジェクトに変換していってます。</p>

<p><code>arel.xxx</code>が連なってる感じ、壮観です。</p>

<h2><code>find_by_sql</code></h2>

<p>この時点では<code>arel</code>はSQLになっていません。</p>

<p>なので、<code>find_by_sql</code>の中を追っていくことにします。</p>

<p>追っていくと、
<code>ActiveRecord::ConnectionAdapters::DatabaseStatements#select_all</code>
に行き着きます。</p>

<p><code>DatabaseManager#to_sql</code>の中の
<code>visitor.accept(arel.ast) do ...</code> というのが、
<code>Arel::TreeManger#to_sql</code>と同じことをやっているのが分かります。</p>

<p>というわけで、ここに来て、Arelのオブジェクトが無事SQLに変換されて、
DBMに向けて投げられたことが分かりました。</p>

<p>めでたし。</p>

<h2><code>to_a</code>は誰が呼ぶ？</h2>

<p><code>to_a</code>を呼び出せば、SQLが発行されることは分かりましたが、
誰がどのタイミングで<code>to_a</code>を呼ぶのでしょうか？</p>

<p>そういえば、<code>where</code>の検索結果に対しては、<code>each</code>メソッドを呼べます。</p>

<p><code>each</code>がどこで定義されているのか調べてみました。</p>

<p>なるほど。
<code>each</code>とか<code>map</code>などが呼ばれたタイミングで、<code>to_a</code>にデリゲートされると。</p>

<h2><code>Relation#inspect</code></h2>

<p>では、たとえば、irbの中で、<code>&gt; p User.where(...)</code>などとしたときはどうなんでしょうか？</p>

<p>このときも<code>to_a</code>が呼ばれるのでしょうか？</p>

<p><a href="http://doc.ruby-lang.org/ja/1.9.2/class/Object.html">http://doc.ruby-lang.org/ja/1.9.2/class/Object.html</a>によると↓とのこ
とです。</p>

<blockquote><p>  inspect -> String</p>

<pre><code>  オブジェクトを人間が読める形式に変換した文字列を返します。

  組み込み関数 Kernel.#p は、このメソッドの結果を使用して オブジェクトを表示します。
</code></pre></blockquote>

<p><code>p</code>は<code>inspect</code>の結果を表示するようです。</p>

<p><code>Relation#insepct</code>は</p>

<p>となってます。</p>

<p>やっぱり、<code>to_a</code>が呼ばれるようです。</p>

<h2>まとめ</h2>

<p>Arelのときもそうでしたが、
<code>where</code>などのメソッドが呼ばれた時点では単に引数だけを保存しておいて、
必要になった時点でSQLを発行するということでした。</p>

<p>「必要になった時点」の判断の仕方が面白いと思いました。</p>

<p>必要になった時点で<code>to_a</code>を呼ぶわけですが、<code>each</code>から<code>to_a</code>にdelegateされるとか、
<code>inspect</code>の中で<code>to_a</code>を呼ぶとか。</p>

<p>しかし、<code>where</code>とかをわざわざActiveRecordでラップする必要があるんですかね&#8230;
<code>Relation</code>のなかでArelのオブジェクトを保持しておいて、<code>where</code>の処理はArelにまかせて、
<code>Relation</code>は<code>to_a</code>とかのまわりだけ面倒みたらだめなのかな&#8230;？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux from Scratch 始めます]]></title>
    <link href="http://ojima-h.github.com/blog/2012/10/19/linux-from-scratch-number-0/"/>
    <updated>2012-10-19T18:08:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/10/19/linux-from-scratch-number-0</id>
    <content type="html"><![CDATA[<p>前々からやる、やる、と言っていた Linux from Scratch に手をつけようと思います。</p>

<p>Linux from scratch (LFS) ていうのは、</p>

<blockquote><p>  Linux From Scratch(リナックス フロム スクラッチ、LFS)とは、Linuxを1から構築しようという試みである。すなわち、カーネルなども含めてすべて手作業でソースコードからコンパイルして作り上げる。</p>

<p>  具体的には、まず現在動作しているLinuxシステム上で、LFSをコンパイルするためのシステムを構築する。そのシステム上で、実際に稼働するLFSのシステムをコンパイルし、実際に起動することが出来る状態にまでもって行くという手順を踏む。</p>

<p>  ref. http://ja.wikipedia.org/wiki/Linux_from_Scratch</p></blockquote>

<p>ということです。でもって、</p>

<blockquote><p>  LFS teaches people how a Linux system works internally
  Building LFS teaches you about all that makes Linux tick, how things work together and depend on each other. And most importantly, how to customize it to your own tastes and needs.</p>

<p>  ref. http://www.linuxfromscratch.org/lfs/</p></blockquote>

<p>楽しく勉強できる、ということのようです。</p>

<p>本家 : <a href="http://www.linuxfromscratch.org">http://www.linuxfromscratch.org</a></p>

<h2>準備</h2>

<p><a href="http://www.linuxfromscratch.org/lfs/downloads/stable/">http://www.linuxfromscratch.org/lfs/downloads/stable/</a> から、LFS-BOOK-7.2.pdf もしくは、LFS-BOOK-7.2.tar.bz (HTMLが入ってる)をダウンロードします。このBOOKに従って粛々とビルドしていきます。</p>

<p>次に、適当なマシンにLinuxをインストールします。LFSやるなら、32bitマシンが無難ぽいです。</p>

<p>というわけで、Core 2 Quad のマシンにGentooをインストールしました。安心の最小構成です。
手元のノートからSSHでアクセスすることにします。</p>

<p>Gentooがインストールされたシステムを「ホスト」と呼びます。
ホスト側で最小限のシステムをビルドした後、新しく構築した側のシステムに移りビスドを進めていくという
流れです。</p>

<h2>パーティション作成</h2>

<p>LFSをビルドするために、新しいのパーティションを作ります。今回は10GBとしました。
スワップ領域、ブートパーティションはホストと共有することにました。</p>

<p>新しくつくったパーティションを<code>/mnt/lfs</code>以下にマウントし、そこにソースをダウンロードしてきます。</p>

<p>ダウンロードするべきソースのリストは、<a href="http://www.linuxfromscratch.org/lfs/downloads/stable/LFS-BOOK-7.2.tar.bz2">http://www.linuxfromscratch.org/lfs/downloads/stable/LFS-BOOK-7.2.tar.bz2</a> に含まれる wget-list にあります。md5sum も含まれています。</p>

<p>あとはユーザを作って、環境変数を調整したり&#8230; 詳しくはLFS-BOOK参照。</p>

<p>これで、ソースが手に入ったので、あとはひたすらビルドしてくだけなんですかね&#8230;？そうだといいですね。</p>

<p>とりあえず、今日はここまで。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[arel #2]]></title>
    <link href="http://ojima-h.github.com/blog/2012/10/16/arel-number-2/"/>
    <updated>2012-10-16T03:30:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/10/16/arel-number-2</id>
    <content type="html"><![CDATA[<p>arel-3.0.2 での以下のコードの実行過程を追い掛けています。</p>

<h2><code>Table#[]</code></h2>

<p>次に、<code>books[:title]</code> の部分について見ます。</p>

<p><code>Table::[]</code>は、<code>Arel::Attribute.new</code>を呼びだしています。</p>

<h3><code>Attribute</code> と <code>Struct</code> について</h3>

<p><code>Struct</code>とは、、、</p>

<blockquote><p>  構造体クラス。Struct.new はこのクラスのサブクラスを新たに生成します。
  個々の構造体はサブクラスから Struct.new を使って生成します。</p>

<p>  ref. <a href="http://doc.ruby-lang.org/ja/1.9.3/class/Struct.html">http://doc.ruby-lang.org/ja/1.9.3/class/Struct.html</a></p></blockquote>

<p>クラスを作るコンストラクタって何だよ&#8230;</p>

<p>arel/attributes/attribute.rb では以下のように使われています。</p>

<p><code>Arel::Predications</code> では例えば次のようなメソッドを定義しています。</p>

<ul>
<li>Arel::Predications#not_eq</li>
<li>Arel::Predications#not_eq_any</li>
<li>Arel::Predications#not_eq_all</li>
<li>Arel::Predications#eq</li>
<li>Arel::Predications#eq_any</li>
</ul>


<p>つまり、<code>Attribute</code> という構造体(のサブクラス)に対して、比較や算術演算などができるようになっている、ということです。</p>

<p><code>Table#[]</code> はこの拡張された構造体を返していることが分かります。</p>

<p>つまり、<code>books[:title].relation</code>には<code>self</code>が、<code>books[:title].name</code>には<code>:title</code>が格納されます。
さらに、<code>books[:title]</code>は<code>Predications</code>モジュールから取り込まれた<code>eq</code>というメソッドをもっています。</p>

<p>ちなみに、<code>::Arel::Attribute.new</code>としていますが、<code>Arel::Attribute</code>は<code>Arel</code>モジュールの定数で、
実体は<code>Arel::Attributes::Attribute</code>クラスです。</p>

<h2><code>Predications#eq</code></h2>

<p><code>Predications#eq</code>は↓</p>

<p><code>Nodes::Equality</code>クラスは、<code>Binary</code>を継承しています。</p>

<p><code>Binary</code>のコンストラクタは、単に引数を記憶しておくだけです。</p>

<p>この時点では、具体的な処理はまだ何もしていません。</p>

<p><code>eq</code>メソッドは<code>Arel::Nodes::Equalitiy</code>クラスのインスタンスを返します。</p>

<h3><code>Class.new</code> と <code>const_set</code></h3>

<p>話は逸れますが、binary.rbに以下のような記述がありました。</p>

<p><code>Module#const_set</code>は、モジュールに定数を定義するメソッドです。</p>

<p><code>Class.new(supercass = Object)</code>は、<code>superclass</code>を親クラスとして匿名クラスをつくります。</p>

<p>Nodeモジュールに、Binaryクラスのサブクラスを値として、各種バイナリオペレータに対応する定数を定義しています。</p>

<p>ぱっとみエグいです。</p>

<h2><code>Table#where</code></h2>

<p><code>books.where</code> を呼びだすと、新たに <code>SelectManager</code>クラスのインスタンスが生成され、
そのインスタンスが保持する<code>wheres</code>というリストに、引数が追加されます。</p>

<p><code>Expressions#eq</code>と同様、引数を記憶しておくだけです。</p>

<h2><code>SelectManager#to_sql</code></h2>

<p>さて、具体的にSQLに変換している部分を見ていくことにします。</p>

<p><code>Table#where</code> を実行すると、<code>SelectManager</code>クラスのインスタンスを返します。</p>

<p><code>SelectManager#to_sql</code> の呼び出しは、継承元の <code>TreeManager</code>クラスに渡ります。</p>

<p><code>engine.connection.visitor</code> ですが、この<code>engine</code>は最初に</p>

<p>ででてきた<code>engine</code>です。</p>

<p>デバッガで、<code>visitor</code>が現れる場所を探していくと、</p>

<p>に行きつきます。ActiveRecord側で何が起きているかは深く考えないことにして、
とにかく、<code>Arel::Visitors::SQLite</code> を見ていくことにします。</p>

<p>結局、<code>TreeManager#to_sql</code> は、<code>Arel::Visitors::ToSql#accept</code>に行き着くことになります。</p>

<p>ちなみに、<code>accept</code> の引数<code>@ast</code>は、<code>books.where</code>を呼びだした時に生成された <code>SelectManager</code>クラスのインスタンスで、これが<code>books.where</code>に渡された引数を保持しています。</p>

<h2><code>Visitors::Visitor</code></h2>

<p><code>Visitors::ToSql</code> は <code>Visitors::Visitor</code> を継承しています。</p>

<p><code>Hash.new {|hash, key| ...}</code> はハッシュのデフォルト値を定めます。<br/>
ref. <a href="http://www.ruby-lang.org/ja/old-man/html/Hash.html">http://www.ruby-lang.org/ja/old-man/html/Hash.html</a></p>

<p>上のコードで、<code>accept</code>に渡される引数は<code>Arel::Nodes::SelectStatement</code>クラスのインスタンスでした。
したがって、<code>dispatch[object.class]</code> が実行された場合、得られる値は<code>"visit_Nodes_SelectStatement"</code>となります。</p>

<p><code>visit</code>では、<code>send</code>メソッドを呼んでいます。<code>send</code>は<code>Object</code>クラスのメソッドで、
<code>obj.send(name,args)</code>は、<code>obj</code>の<code>name</code>メソッドを<code>args</code>を引数として呼びだします。</p>

<p>つまり、<code>ToSql</code>クラスの<code>visit_Nodes_SelectStatement</code>というメソッドが呼ばれることになります。</p>

<p>ちなみに、<code>Visitor</code>クラスのサブクラスには、</p>

<ul>
<li><code>DepthFirst</code></li>
<li><code>Dot</code></li>
<li><code>Informix</code></li>
<li><code>OrderClauses</code></li>
</ul>


<p>などがあります。これらのクラスのインスタンスの<code>visit</code>メソッドを呼びだしたときも、同様の処理が行われることになります。</p>

<h2><code>To_Sql#visit_Nodes_SelectStatement</code></h2>

<p><code>o.cores</code>の中に、<code>books.where</code>に渡された引数が格納されています。</p>

<p>ここで察しがつくかと思いますが、ここから<code>visit</code>を再帰的に呼び出していきます。</p>

<p><code>o.wheres</code> に <code>books.where</code> に渡された引数 <code>books[:title].eq(...)</code> が格納されています。
<code>books[:title].eq(...)</code>のクラスは<code>Arel::Nodes::Equality</code>なので、8行目で<code>visit_Arel_Nodes_Equality</code>が呼ばれます。</p>

<p><code>visit o.left</code>の部分で、<code>books[:title]</code>に対して<code>visit</code>が呼ばれます。</p>

<p>最終的に、<code>"SELECT FORM books WHERE books.title = 'Head First Rails'"</code>という文字列が得られるはずです。</p>

<h2>まとめ</h2>

<p>Arelに特徴的なのは、<code>#where</code> や <code>#eq</code> というメソッドが呼ばれたときに、
特に具体的な変換は行わず、引数や<code>self</code>を保持するインスタンスを返すだけ、ということではないでしょうか。</p>

<p>いってみれば、<code>#where</code>や<code>#eq</code>などを使いながら「SQL構文木」を構築していくのだと思います。</p>

<p><code>#to_sql</code>が呼ばれたときに、この「構文木」のノードや葉を対応するSQLに変換していくわけです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[arel #1]]></title>
    <link href="http://ojima-h.github.com/blog/2012/10/15/arel-number-1/"/>
    <updated>2012-10-15T00:00:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/10/15/arel-number-1</id>
    <content type="html"><![CDATA[<p>Arelとは、SQLクエリを構築するためのrubyのライブラリです。</p>

<p>ActiveRecord(モデル層)とデータベースの間に立ち、
ActiveRecordにおけるメソッド呼び出しをSQLクエリに変換してくれます。<br/>
ref. <a href="http://gihyo.jp/dev/serial/01/ruby/0043">http://gihyo.jp/dev/serial/01/ruby/0043</a></p>

<p>arel-3.0.2、activerecord-3.2.8 を使ってます。</p>

<p>目標は、次のコードの実行過程を理解すること。</p>

<pre><code>books = Arel::Table.new :books
books = books.where(books[:title].eq('Head First Rails'))
puts books.to_sql
</code></pre>

<p>このコードを実行すると、<code>SELECT FROM books WHERE books.title = 'Head First Rails'</code>という文字列が返ってきます。</p>

<hr />

<p>Arel を使うためには、データベースとのコネクションを作る必要があるのですが、
その部分は ActiveRecord のおまかせします。</p>

<pre><code>require 'arel'
require 'sqlite3'
require 'active_record'

ActiveRecord::Base.configurations = {'development' =&gt; {:adapter =&gt; 'sqlite3', :database =&gt; 'books.sqlite3'}}
ActiveRecord::Base.establish_connection('development')

Arel::Table.engine = ActiveRecord::Base
</code></pre>

<hr />

<p>さて、つらつらと読んでいくことにします。</p>

<p>でも、眠いので今日はここまで。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[rails sourcecode reading #3 -- 準備]]></title>
    <link href="http://ojima-h.github.com/blog/2012/10/14/rails-sourcecode-reading-number-3/"/>
    <updated>2012-10-14T23:20:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/10/14/rails-sourcecode-reading-number-3</id>
    <content type="html"><![CDATA[<p>まずは、ソースコードを用意しました。
bundle を利用することにしました。</p>

<pre><code>$ mkdir rails_sourcecode_reading
$ cd rails_sourcecode_reading
$ mkdir src

$ vi Gemfile

-----------------------------
# Gemfile
source "http://rubygems.org"

gem "rails", "3.2.8"
-----------------------------

$ bundle install --path="./src"
</code></pre>

<p>これで、src/ruby/1.9.1/gems 以下に、railsに関連するgemたちが全部入ります。</p>

<p>次に、ソースコードを読む環境を整えました。
もちろん、emacsで読んでいきます。
以下は、利用した elisp とか gem とかです。</p>

<ul>
<li><p>ctags</p>

<p><code>ctags -e -R . --langmap=Ruby:.rb --ruby-types=cfFm</code> でemacs用のタグファイルを生成し、
<code>M-.</code> でタグジャンプできます。</p>

<p>参考 : <a href="http://wiki.livedoor.jp/koziy/d/ruby/ctags">http://wiki.livedoor.jp/koziy/d/ruby/ctags</a></p></li>
<li><p>rdefs (gem)</p></li>
<li><p>rinari (elisp)</p>

<p>packege-install ではいります。
rails 用の統合開発環境みたいなかんじです。</p></li>
<li><p>ruby-debug</p>

<p><a href="http://jampin.blog20.fc2.com/blog-entry-18.html">http://jampin.blog20.fc2.com/blog-entry-18.html</a> を参考に。</p></li>
<li><p>yard</p>

<p><code>yard server</code> でWebサーバ起動</p></li>
</ul>


<p>まずは、ActiveRecord と Arel あたりから読んでいこうと思います。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[rails sourcecode reading #2]]></title>
    <link href="http://ojima-h.github.com/blog/2012/10/14/rails-sourcecode-reading-number-2/"/>
    <updated>2012-10-14T23:20:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/10/14/rails-sourcecode-reading-number-2</id>
    <content type="html"><![CDATA[<p>ruby の勉強と Webアプリケーションフレームワークの勉強のために、
Rails のソースコードをじっくり読んでいこう、と思い立ちました。</p>

<p>そろそろまじめにやろうと思います。</p>

<p>勉強したことは、このページに書いていきます。</p>

<p>ruby のバージョンは 1.9.3p194、rails のバージョンは 3.2.8 です。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[arel #1]]></title>
    <link href="http://ojima-h.github.com/blog/2012/10/14/arel-number-1/"/>
    <updated>2012-10-14T23:20:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/10/14/arel-number-1</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dzenで日本語]]></title>
    <link href="http://ojima-h.github.com/blog/2012/07/15/dzen-with-japanese/"/>
    <updated>2012-07-15T04:38:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/07/15/dzen-with-japanese</id>
    <content type="html"><![CDATA[<p>dzen で日本語を表示するまでのまとめ。</p>

<p>portage で提供されている dzen をインストールしたところ、日本語が化けた。</p>

<p>どうやら、xft のサポートをつける必要があるみたい。</p>

<p>ところが、通常のレポジトリで提供されているソースは xft に対応していないようだ。</p>

<p>というわけで、<a href="https://github.com/robm/dzen">https://github.com/robm/dzen</a> から最新版をもってきて、普通に make してインストールしたら、表示できました。</p>

<p>ちなみに、フォントを指定してやらないと、かなり汚い。アンチエイリアスも設定できた。</p>

<pre><code>dzen2 -fn 'xft\
          \:IPAGothic\
          \:pixelsize=13\
          \:weight=regular\
          \:width=semicondensed\
          \:dpi=96\
          \:hinting=true\
          \:hintstyle=hintslight\
          \:antialias=true\
          \:rgba=rgb\
          \:lcdfilter=lcdlight\
          \'
</code></pre>

<p>一応ebuildをのっけてみる。。。</p>

<p><a href="https://github.com/ojima-h/my-overlays/blob/master/x11-misc/dzen/dzen-9999.ebuild">https://github.com/ojima-h/my-overlays/blob/master/x11-misc/dzen/dzen-9999.ebuild</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ip address and network address]]></title>
    <link href="http://ojima-h.github.com/blog/2012/05/09/ip-address-and-network-address/"/>
    <updated>2012-05-09T03:17:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/05/09/ip-address-and-network-address</id>
    <content type="html"><![CDATA[<p>ネットワークについて勉強していたので、そのまとめ兼メモ。</p>

<hr />

<p>192.168.0.0 ~ 192.168.255.255 のIPを用いてネットワークを構築しようと考えます。</p>

<p>このとき、全てのコンピュータを 同じネットワーク下 (192.168.0.0/16) に置
いてもいいのですが、それだと管理が大変です。そこで、サブネットに分割す
ることを考えます。</p>

<p>部署Aには、IPは 192.168.1.0 ~ 192.168.1.255、 サブネットは 192.168.1.0/24 を用いてネットワークを構築するよう依頼します。</p>

<p>部署Bには、IPは 192.168.2.0 ~ 192.168.2.255、 サブネットは 192.168.2.0/24 を用いてネットワークを構築するよう依頼します。</p>

<p>それぞれのネットワークに属するコンピュータはハブを介して接続します。</p>

<p>これらのネットワーク同士を接続するために、もうひとつサブネット
192.168.3.0/24 を用意します。更に、サブネット 192.168.1.0/24、
192.168.2.0/24 のそれぞれの内部にルータを設置し、そのルータの他方の口を
192.168.3.0/24 のネットワークにつなぎます。これで、192.168.1.0/24 と
192.168.2.0/24 の間で相互に通信することができます。</p>

<p>これらのプライベートネットワークからインターネットに接続するには、
192.168.3.0/24 のネットワークの中にNAT機能を備えたルータが必要。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[emacs-overlay で Elisp を管理 -- その2 (プロキシ越しにsvnプロトコル)]]></title>
    <link href="http://ojima-h.github.com/blog/2012/05/03/gentoo-emacs-overlay-2/"/>
    <updated>2012-05-03T02:55:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/05/03/gentoo-emacs-overlay-2</id>
    <content type="html"><![CDATA[<p>大学のプロキシ内からだと svn プロトコルが通らず、emacs-overlay を layman に追加できなかった。</p>

<p>それを無理矢理なんとかするまでの記録。</p>

<ol>
<li><p><code>layman -a emacs</code> するもタイムアウトのエラーが発生。</p>

<p><code>/usr/bin/svn co svn://overlays.gentoo.org/proj/emacs/emacs-overlay/@ /var/lib/layman/emacs</code> でコケるようだ。</p></li>
<li><p>直接、<code>/usr/bin/svn co svn://overlays.gentoo.org/proj/emacs/emacs-overlay/@ emacs</code> を実行してみるも、やはりムリ。</p></li>
<li><p>ならばと、<code>/usr/bin/svn co https://overlays.gentoo.org/proj/emacs/emacs-overlay/@ emacs</code> を実行してみるも、やはりムリ。</p>

<pre><code>svn: パス 'https://overlays.gentoo.org/proj/emacs/emacs-overlay' が見つかりません
</code></pre>

<p>とか言われる。</p></li>
<li><p>困る。</p>

<p>SSHトンネル掘ってナントカ。。。とかヨクワカラナイコトを考えた挙句、VPS に emacs-overlay のクローンを置いて http でアクセスすることにする。
ちなみに、VPS の方は Debian です。</p></li>
</ol>


<h2>VPS に emacs-overlay のクローンを置いて http でアクセス</h2>

<p>Apache はセットアップ済みで、公開ディレクトリは /var/www であるものとします。</p>

<ol>
<li><p>git-svn をインストール</p>

<pre><code>aptitude install git-svn
</code></pre></li>
<li><p>emacs-overlay をコピーしてくる。</p>

<pre><code>git svn clone svn://overlays.gentoo.org/proj/emacs/emacs-overlay/ emacs-overlay
</code></pre></li>
<li><p>公開ディレクトリに bare レポジトリを置く。</p>

<pre><code>cd /var/www/
git clone /path/to/emacs-overlay emacs-overlay.git --bare
</code></pre></li>
</ol>


<p>これで、<code>git clone http://xxxxxx/emacs-overlay.git</code> でクローンできるようになっているはず。</p>

<h2>layman の overlay のリストに追加する</h2>

<ol>
<li><p>/var/lib/layman/my-list.xml を作成して、次のような内容を書く。</p>

<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE repositories SYSTEM "/dtd/repositories.dtd"&gt;
&lt;repositories xmlns="" version="1.0"&gt;
  &lt;repo quality="experimental" status="official"&gt;
    &lt;name&gt;&lt;![CDATA[emacs-clone]]&gt;&lt;/name&gt;
    &lt;description&gt;&lt;![CDATA[Provide Emacs related ebuilds which are a bit experimental or
    work-in-progress. Don't rely on them, but don't hesitate to file bugs or
    write emails.]]&gt;&lt;/description&gt;
    &lt;homepage&gt;http://your/homepage/uri&lt;/homepage&gt;
    &lt;owner type="project"&gt;
      &lt;email&gt;sample@example.com&lt;/email&gt;
    &lt;/owner&gt;
    &lt;source type="git"&gt;http://server/uri/emacs-overlay.git&lt;/source&gt;
  &lt;/repo&gt;
&lt;/repositories&gt;
</code></pre></li>
<li><p>/etc/layman/layman.cfg に次のような内容を書く:</p>

<pre><code>.....

overlays  : http://www.gentoo.org/proj/en/overlays/repositories.xml
            file:///var/lib/layman/my-list.xml

.....
</code></pre></li>
<li><p>layman を更新する。</p>

<pre><code>layman -S
</code></pre></li>
<li><p><code>layman -L</code> を実行して、いま追加したオーバレイが表示されれば OK.</p></li>
</ol>


<hr />

<p>振り返ってみると、がんばったわりに得るものが少ない気が。。。</p>

<p>あとは、更新が面倒くさそう。Git の bare レポジトリって直接更新できないのかな&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[emacs-overlay で Elisp をパッケージ管理]]></title>
    <link href="http://ojima-h.github.com/blog/2012/05/02/gentoo-emacs-overlay/"/>
    <updated>2012-05-02T22:59:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/05/02/gentoo-emacs-overlay</id>
    <content type="html"><![CDATA[<p>関西 Emacs で Elisp のパッケージ管理の話が出てきたことだし、
portage で Elisp を管理してみることにする。</p>

<p>こういうのって、まずは Overlay から見てみるものなのかな&#8230;</p>

<p>ということで、emacs-overlay を使ってみる。</p>

<p>参考: <a href="http://overlays.gentoo.org/proj/emacs/">http://overlays.gentoo.org/proj/emacs/</a></p>

<ol>
<li><p>layman をインストール</p>

<pre><code>emerge layman
</code></pre></li>
<li><p>emacs-overlay を追加</p>

<pre><code>layman -a emacs
</code></pre></li>
<li><p>layman をソースに追加。</p>

<pre><code>echo "source /var/lib/layman/make.conf" &gt;&gt; /etc/make.conf
</code></pre></li>
</ol>


<p><code>/var/lib/layman/emacs/app-emacs/</code> とかを見るとインストールできる Elisp が見える。</p>

<p>anything とか evil とかあるけど、、、、<br/>
あんまり数は無いのね&#8230;.</p>

<hr />

<p>ちなみに大学のプロキシ内からだと、svn プロトコルが通らずハマったけれど、
それはまた別のお話。</p>

<p><a href="http://ojima-h.github.com/blog/2012/05/03/gentoo-emacs-overlay-2/">emacs-overlay で Elisp をパッケージ管理 その2</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails SourceCode Reading #1]]></title>
    <link href="http://ojima-h.github.com/blog/2012/04/22/rsr-1/"/>
    <updated>2012-04-22T19:42:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/04/22/rsr-1</id>
    <content type="html"><![CDATA[<h2>前半は Ruby の基礎のお話。</h2>

<p><a href="http://i.loveruby.net/ja/rhg/book/minimum.html">http://i.loveruby.net/ja/rhg/book/minimum.html</a> に沿って話した。</p>

<p>要は、<strong>全てのモノはオブジェクトである</strong>、というお話。</p>

<p>話したこととしては、</p>

<ul>
<li>クラスは Class というクラスのインスタンスである。</li>
<li>モジュールは Module というクラスのインスタンスである。</li>
<li>Module クラスは Class クラスのインスタンスである。</li>
<li>Class クラスは Class クラスのインスタンスである。</li>
<li><p>すべてのクラスは superclass に Object を持つ。
Object クラスの superclass は nil である。</p>

<p>(今は、Object クラスの superclass は BasicObject になっているぽい。)</p>

<p>(今日話したときは、「全てのオブジェクトは Object を superclass に持つ」とか言ってた気がする)</p></li>
</ul>


<p>とかとか。</p>

<p>一応整理しておくと、</p>

<ul>
<li>オブジェクト間の関係

<ul>
<li>クラス - インスタンスの関係</li>
<li>is_a 関係</li>
</ul>
</li>
<li>クラス間の関係

<ul>
<li>継承関係</li>
<li>ネスト</li>
</ul>
</li>
</ul>


<p>今日話した時は、クラス - インスタンスの関係と is_a 関係を混同していた&#8230;</p>

<h3>is_a 関係について</h3>

<p><a href="http://d.hatena.ne.jp/willnet/20080523/1211512760">http://d.hatena.ne.jp/willnet/20080523/1211512760</a></p>

<p><code>foo.is_a? Foo</code> が真になるのは、</p>

<ul>
<li>foo が Foo のインスタンスであるとき</li>
<li>foo が Foo のサブクラスのインスタンスであるとき</li>
<li>foo が モジュール Foo をインクルードしたクラスのインスタンスであるとき</li>
<li>foo が モジュール Foo をインクルードしたクラスのサブクラスのインスタンスであるとき</li>
</ul>


<p>あとは、特異メソッドの話。</p>

<p>結局、<code>include</code> と <code>extend</code> の違いを説明したかっただけな気がする。</p>

<h2>後半は ActiveRecord の解読</h2>

<p><a href="http://ojima-h.github.com/rails-sourcecode-reading-slide-1/">http://ojima-h.github.com/rails-sourcecode-reading-slide-1/</a></p>

<pre><code>@@@ ruby
rails generate scaffold Foo foo:string
</code></pre>

<p>てやったときにできる <code>Foo#foo</code> ていうメソッドがどうやって定義されているのかを解説した。</p>

<ul>
<li>missing_method コワイ</li>
<li>eval コワイ</li>
</ul>


<p>という結論でした。</p>

<h2>ツールについて</h2>

<ul>
<li>showoff が便利</li>
<li>rdefs.el が便利だけど、使いにくい。
せめて、バッファがリードオンリーなのをなんとかしたい。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[showoff 使ってみた]]></title>
    <link href="http://ojima-h.github.com/blog/2012/04/22/showoff-intro/"/>
    <updated>2012-04-22T14:00:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/04/22/showoff-intro</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/schacon/showoff">https://github.com/schacon/showoff</a></p>

<p>Ruby + Markdown で HTML なスライドをつくれる、ということで、使ってみた。</p>

<p>感想は</p>

<ul>
<li>Markdown やっぱり素敵</li>
<li>Markdown から直にプレビューできる</li>
<li>コマンド一発で github page に公開できるのが便利</li>
<li>ある程度きれいにみせようと思ったら、CSS と javascript がんばって書
かないといけない</li>
<li>一枚のスライドのなかで内容を少しづつ見せる、ってことができなかった</li>
</ul>


<p>てかんじでした。</p>

<hr />

<p>使うまでの記録を書いておく。</p>

<h2>とりあえず使う</h2>

<p>まずはインストール。</p>

<pre><code>gem install showoff
</code></pre>

<p>新規プレゼンテーションの作成</p>

<pre><code>showoff create new_presentation
cd new_presentation
</code></pre>

<p>すると、&#8221;one&#8221; というディレクトリの下に &#8220;01_slide.md&#8221; というファイルが
できているはず。</p>

<p>この &#8220;01_slide.md&#8221; にマークダウンで色々書いていけばよい。</p>

<p><code>!SLIDE</code> という行があると、そこでスライドが切り替わる。</p>

<p>コマンドラインから</p>

<pre><code>$ showoff serve
</code></pre>

<p>を実行し、<code>localhost:9090</code> にアクセスすると、プレビューを見ることがで
きる。</p>

<p>ちなみに、Firefox + Vimperator を使っているとスライドの操作ができない
ので注意。<code>Shift + escape</code> で Vimperator のキーを無効にすれば大丈夫。</p>

<p>さらに、</p>

<pre><code>$ showoff static
</code></pre>

<p>で、&#8221;static&#8221; というディレクトリができて、その中に整形された HTML が吐かれる。</p>

<p>詳しい使いかたは <a href="https://github.com/schacon/showoff">https://github.com/schacon/showoff</a> を参照。</p>

<h2>github pages への公開方法</h2>

<p>まずは、ソース全体を公開するためのレポジトリを作成。
全部のファイルをコミットする。</p>

<p>そしたら、おもむろに</p>

<pre><code>$ showoff github
</code></pre>

<p>これで、&#8221;gh_pages&#8221; というブランチに、<code>showoff static</code> されたコードをコ
ミットしてくれる。</p>

<p>あとは、<code>git push orgin gh-pages</code> するだけで、
&#8220;username.github.com/repository-name/&#8221; にスライドが公開される。</p>

<hr />

<p>うーん、やっぱりちょっとづつ表示していくのが欲しいな&#8230;.
javascript でできるのかな&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[cucumber + rspec + webrat の落とし穴]]></title>
    <link href="http://ojima-h.github.com/blog/2012/04/16/cucumber-rspec-webrat-install/"/>
    <updated>2012-04-16T21:17:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/04/16/cucumber-rspec-webrat-install</id>
    <content type="html"><![CDATA[<p>cucumber + rspec + webrat ではまったのでメモ。</p>

<h2>visit が効かない</h2>

<pre><code>When /^visit "(.*)"$/ do |page|
  visit page
  p response
end
</code></pre>

<p>ってやると、<code>nil</code> が表示される。。。</p>

<p>調べていくと、こんなページを発見。</p>

<p><a href="http://forums.pragprog.com/forums/95/topics/4951">http://forums.pragprog.com/forums/95/topics/4951</a></p>

<p>とりあえず、features/support/env.rb に以下を追加。</p>

<pre><code>require 'webrat'

Webrat.configure do  |config|
  config.mode = :rack
end
</code></pre>

<p>そしたら、こんなエラーが発生。。。</p>

<pre><code>No response yet. Request a page first. (Rack::Test::Error)
</code></pre>

<p><a href="http://forums.pragprog.com/forums/95/topics/8962">http://forums.pragprog.com/forums/95/topics/8962</a></p>

<p>このページを参考に、step の定義を次のように変更.</p>

<pre><code>When /^visit "(.*)"$/ do |url|
  visit url
  p page
end
</code></pre>

<p>無事実行されました。</p>

<h2>have_tag にブロックを渡せない</h2>

<pre><code>page.body.should have_selector('a') do |a|
  p a
end
</code></pre>

<p>ってやっても期待する結果が得られない。。。</p>

<p>未だ解決策みつからず。</p>

<p>まぁ、いいか</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tree]]></title>
    <link href="http://ojima-h.github.com/blog/2012/04/16/tree-command/"/>
    <updated>2012-04-16T19:51:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/04/16/tree-command</id>
    <content type="html"><![CDATA[<p>&#8220;tree&#8221; っていうコマンドが面白い。</p>

<pre><code>emerge app-text/tree
</code></pre>

<p>こんなかんじで表示される</p>

<pre><code>$ tree a
a
|-- b
|   `-- c
`-- d
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Github pages + Octpress]]></title>
    <link href="http://ojima-h.github.com/blog/2012/04/15/github-pages-and-octpress/"/>
    <updated>2012-04-15T13:44:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/04/15/github-pages-and-octpress</id>
    <content type="html"><![CDATA[<p>GitHub Pages + Octpressでブログ立ち上げるまでの記録。</p>

<ul>
<li><a href="http://mattn.kaoriya.net/software/lang/ruby/20111017205717.htm">http://mattn.kaoriya.net/software/lang/ruby/20111017205717.htm</a></li>
<li><a href="http://octopress.org/docs/setup/">http://octopress.org/docs/setup/</a></li>
<li><a href="http://octopress.org/docs/deploying/github/">http://octopress.org/docs/deploying/github/</a></li>
<li><a href="http://octopress.org/docs/blogging/">http://octopress.org/docs/blogging/</a></li>
</ul>


<p>を参考に。</p>

<p>環境は、Gentoo-3.2.1-r2 / ruby 1.9.3p0</p>

<ol>
<li><p><em>username</em>.github.com というレポジトリを新規作成</p></li>
<li><p>Octpressのソースを取得。</p>

<pre><code>git clone https://github.com/imathis/octopress
cd octopress
</code></pre></li>
<li><p>インストール</p>

<pre><code>rake install
rake setup_github_pages
</code></pre>

<p><code>rake setup_github_pages</code> するとGitレポジトリのURIを聞かれるので、
さっき作ったレポジトリ (= <code>git@github.com/username/username.github.com</code>) を指定する。
ここで、<code>.git/config</code>を書き換えて、orgin とかを設定してくれるぽい。</p></li>
<li><p>とりあえず、なにか投稿してみる。</p>

<pre><code>rake new_post["hello world"]
</code></pre>

<p>&#8220;hello world&#8221;の部分はポストのタイトルを指定します。
ここで指定したものがURLになります。<br/>
(実際は、<code>.../:year/:month/:day/:title</code>ってかんじ)</p>

<p>ページに表示されるタイトルはあとからいじれます。</p>

<p>実行すると、<code>source/_posts/&lt;yaer&gt;-&lt;month&gt;-&lt;day&gt;-hello-world.markdown</code>というファイルが
生成されます。</p>

<pre><code>---
layout: post
title: こんにちは
date: 2012-04-14 23:31
comments: true
categories: diary
---

こんにちは! 世界!
------------------

むにゃむにゃ
</code></pre>

<p>こんなかんじて適当に編集します。</p></li>
<li><p>さあ、公開してみましょう</p>

<p>今作成したファイルをデプロイ用のディレクトリにコピーします。</p>

<pre><code>rake generate
</code></pre>

<p>この段階では、まだアップロードされてません。</p>

<p>アップするまえにローカル環境で確認することができます。</p>

<pre><code>rake preview
</code></pre>

<p>として、<code>localhost:4000</code>にアクセスすればおけ。</p>

<p>問題がないようなら、githubにあげます。</p>

<pre><code>rake deploy
</code></pre></li>
<li><p>成功していれば (失敗しても)、githubからメールが来ます。</p></li>
</ol>


<p>ちなみに <code>rake deploy</code>でpushされるのは、public/ 以下の内容のみ。
ソース全体もpushしておきましょう。(って書いてあった)</p>

<pre><code>git add .
git commit -m "message"
git push origin source
</code></pre>

<hr />

<p>なにが便利かっていうと</p>

<ul>
<li>手元で編集できる。Emacsとかでね。</li>
<li>localhost でプレビューできる。</li>
<li>rake 一発で公開できる。</li>
</ul>


<p>そういえば、Octpressみたいな形で配布されるアプリ(？)って初めて見た。<br/>
たしかに、Rakefile に色々書いておけばシステムにインストールする必要ないしな。。。</p>

<p>それにしても便利。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第0回 Railsソースコードリーディング]]></title>
    <link href="http://ojima-h.github.com/blog/2012/04/14/rails-sourcecode-reading-0/"/>
    <updated>2012-04-14T23:31:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/04/14/rails-sourcecode-reading-0</id>
    <content type="html"><![CDATA[<p>なんとなくで始めみてみたRailsソースコードリーディング。
手探りながらの第0回でした。</p>

<p>まぁ、ぐだぐだ、でした</p>

<p>今日のお題は</p>

<p><strong>Railsの概要と基本的な使い方</strong></p>

<p>まずは、MVCに関するお話。<br/>
MVCとは、アプリケーションの構成を</p>

<ul>
<li>M (=Model)
データを管理するコンポーネント</li>
<li>V(=View)
ユーザの目の前に表示される部分を管理するコンポーネント</li>
<li>C(=controller)
ModelとViewのあいだをとりもつコンポーネント</li>
</ul>


<p>の3つに分けて捉えましょう、という考えかた。</p>

<p>一方で、Railsの構成がどうなっているかというと、、、</p>

<p>実はRails本体はからっぽで、実体は次のようなライブラリ群からできている。</p>

<ul>
<li><p>ActionPack</p>

<ul>
<li>ActionController</li>
<li>ActionView</li>
<li>ActionDispatch</li>
</ul>
</li>
<li><p>ActiveRecord</p></li>
<li><p>ActiveModel</p></li>
<li><p>ActiveResource</p></li>
<li><p>etc&#8230;</p></li>
<li><p>railties</p></li>
</ul>


<p>そして、M,V,C のそれぞれと、 Railsの各構成要素のそれぞれが一対一に対応している。</p>

<ul>
<li>Model &lt;=> ActiveRecord, ActiveModel, ActiveResource</li>
<li>View &lt;=> ActionView</li>
<li>Controller &lt;=> ActionController, ActionDispatch</li>
</ul>


<p>そしてそして、railtiesがこれらのライブラリ群をまとめあげて、コマンドラインインターフェイスを提供していると。。。</p>

<p>というわけで、次回以降はライブラリ群を1つ1つ読み解いていこう!! というお話でした。</p>

<p>とりあえず、次回はActiveRecordで。来週です。</p>

<hr />

<p>さてさて、Railsの簡単な使いかたを勉強しましょう、ということになりました。</p>

<pre><code>rails new sample
</code></pre>

<p>からはじめて、</p>

<pre><code>rails generate scaffold pages title:string content:text
</code></pre>

<p>ここまでは何の問題もなかったんです。</p>

<p>ところが</p>

<pre><code>rake db:migrate
</code></pre>

<p>したところ、、、</p>

<p><strong>全員エラー!!!</strong></p>

<p>しかも、エラーメッセージが意味不明だし。</p>

<p>そんなこんなしているうちに時間がきてしまい、結局グダグダになってしまいました。</p>

<p>はぁ、書くの飽きた。。。</p>

<p>まぁ、そんなかんじの第0回でした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[はじめましてのご挨拶]]></title>
    <link href="http://ojima-h.github.com/blog/2012/04/14/hello-world/"/>
    <updated>2012-04-14T23:31:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2012/04/14/hello-world</id>
    <content type="html"><![CDATA[<h2>ブログはじめました</h2>

<p>Railsソースコードリーディングを機に、いまさらながらブログなど始めてみ
ました。</p>

<p>github page + octpress + jekyll 環境でやってます。</p>

<p>テストがてら、初めての投稿。。。</p>
]]></content>
  </entry>
  
</feed>
