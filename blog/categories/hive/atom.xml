<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hive | 毛無しさん@キレートレモン]]></title>
  <link href="http://ojima-h.github.com/blog/categories/hive/atom.xml" rel="self"/>
  <link href="http://ojima-h.github.com/"/>
  <updated>2013-08-30T16:51:21+09:00</updated>
  <id>http://ojima-h.github.com/</id>
  <author>
    <name><![CDATA[ojima_h]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hadoop のチューニングに関してまとめ]]></title>
    <link href="http://ojima-h.github.com/blog/2013/08/29/hadoop-tuning/"/>
    <updated>2013-08-29T16:06:00+09:00</updated>
    <id>http://ojima-h.github.com/blog/2013/08/29/hadoop-tuning</id>
    <content type="html"><![CDATA[<p>1効率の良い HiveQL を書くときに気をつけるべきことをまとめてみる。</p>

<p><em>以下に書いたことは、ほとんど全部自分なりの解釈なので、間違いが多々あると思います</em></p>

<p>Hadoop一般のチューニングに関しては、ここを参考にした。</p>

<p><a href="http://www.cloudera.co.jp/jpevents/cloudera-world-tokyo/pdf/A3_Hadoop%E3%81%AE%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E8%A8%AD%E8%A8%88_%E9%81%8B%E7%94%A8%E3%81%AE%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88.pdf">http://www.cloudera.co.jp/jpevents/cloudera-world-tokyo/pdf/A3_Hadoop%E3%81%AE%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E8%A8%AD%E8%A8%88_%E9%81%8B%E7%94%A8%E3%81%AE%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88.pdf</a></p>

<p><a href="http://www.amazon.co.jp/Hadoop-Tom-White/dp/487311439X">Hadoop本</a> を参考に、この資料の補足してみた↓</p>

<h2>ラック内ネットワークとラック間ネットワークは何が違うのか？</h2>

<p><em>(p.69 「ネットワークトポロジとHadoop」 / p.267 9.1.1 ネットワークトポロジ)</em></p>

<p>Hadoop は、データを読み書きする際にネットワークのトポロジやネットワーク構成を勘案しながら動作する。
読み込みを行う際には、クライアントになるべく <em>近い</em> ノードから読み込むように調整するし、
書き込みを行う際には、データのレプリカが近い場所に集中してしまわないように調整する。</p>

<p>2つのノード間のデータ転送速度が早いほど、この2つのノードが <em>近い</em> と見做される。
Hadoop は、ノード間の距離をネットワーク構成から算出している。
つまり、「同じラックにある2つのノードは互いに近い = 転送速度が早い」ものとして処理を進める。</p>

<p>そのため、同じラック内にあるのに実際には転送速度が遅い、ということになると、
Hadoop が効率良くデータを処理することができなくなってしまう。</p>

<h2>スレーブノードでは、なぜ RAID0 を組んではダメなのか？</h2>

<p><em>(p.266 「RAIDを使わないのはなぜ？」)</em></p>

<ul>
<li>HDFSはノード間の複製によって冗長性を持つので、RAIDで冗長性を提供してもらう必要がない。(←弱い)</li>
<li>RAID0 でデータロストが発生した事例あり</li>
</ul>


<h2>マスターノードでRaidを組まないと何が起きるのか？</h2>

<p>マスターノード (= ネームノード) は、クラスタ上のどのノードにどのファイルのデータが保存されているかを管理している。
マスターノードのデータが壊れると、HDFSからファイルデータを読み取ることができなくなってしまう。</p>

<p>そのため、マスターノードは信頼性を確保しておく必要がある。</p>

<h2>マスターとスレーブで、求められるCPU性能が違うのはなぜ？</h2>

<p>実際に計算するのはスレーブノード。
マスターノードは、クライアントの要求を受けて適切なスレーブノードに指令を出すのが仕事。
だから、マスターノードはたいしてCPU性能を必要としない。</p>

<h2>ECCとはなんぞ？</h2>

<p><a href="http://e-words.jp/w/ECCE383A1E383A2E383AA.html">Error Check and Correct memory</a></p>

<blockquote><p>メモリに誤った値が記録されていることを検出し、正しい値に訂正することができるメモリモジュール。</p></blockquote>

<h2>なんで圧縮したら「速度」があがるの？</h2>

<p>マップタスクからの出力は一時的にディスクに保存される。
レデュースタスクからの出力もディスクに保存される。</p>

<p>一般的には、Hadoopはかなり大きなデータを扱うので、出力結果を圧縮しないままディスクに書き込む時間よりも、
(圧縮する時間 + 圧縮データをディスクに書き込む時間) の方が短くなる。
読み込む時も同様に、非圧縮のデータを読み出す時間よりも、(圧縮されたデータを読み出す時間 + 解凍する時間) の方が短かくなる。</p>

<h2>ブロック数(サイズ)とヒープサイズの関係は？ (16枚目)</h2>

<p>ブロック数が小さい = ブロックサイズが大きい = ディスクから1回に読み込むデータのサイズが大きい = ディスクへのアクセスが減る</p>

<p>ヒープサイズが大きい = 計算結果を沢山メモリに置いておける = 計算結果をディスクに書き出すことが減る = ディスクへのアクセスが減る</p>

<p>⇒ <strong>速い</strong></p>

<h2>フェデレーション？て何？</h2>

<p><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/Federation.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/Federation.html</a></p>

<blockquote><p>The prior HDFS architecture allows only a single namespace for the entire cluster. A single Namenode manages this namespace. HDFS Federation addresses limitation of the prior architecture by adding support multiple Namenodes/namespaces to HDFS file system.</p>

<p>In order to scale the name service horizontally, federation uses multiple independent Namenodes/namespaces. The Namenodes are federated, that is, the Namenodes are independent and don’t require coordination with each other. The datanodes are used as common storage for blocks by all the Namenodes. Each datanode registers with all the Namenodes in the cluster. Datanodes send periodic heartbeats and block reports and handles commands from the Namenodes.</p></blockquote>

<p>ネームノードの性能をスケールさせるために、HDFSファイル空間を2つに分けてしまって2つのネームノードでそれぞれ担当しよう、という話のようだ。</p>

<p>ネームノードの冗長化とはまた別の話なのかな？</p>

<h2>「ディスクのマウントポイントごとに別々のディレクトリをカンマ区切りで指定すること」てどういう意味？(21枚目)</h2>

<p>1つのデータノードのストレージはいくつかのディスクで構成されている。
ディスクが複数あってそれぞれにデータが分散して保存されているから、
データノードは処理を並列して行うことができる。</p>

<p>で、データノードは <code>dfs.datanode.data.dir</code> に指定されたディレクトリに対してラウンドロビンで書き込んでいくから、
<code>dfs.datanode.data.dir</code> には、複数あるディスクのそれぞれのマウントポイントを指定しないとダメだよ、ということ。</p>

<p>ちなみに、JBOD っていうのは、<a href="http://ja.wikipedia.org/wiki/JBOD">http://ja.wikipedia.org/wiki/JBOD</a> 参照。</p>

<h2>「タクク数 > ディスク数」てどういう状態？(25枚目)</h2>

<p>それぞれのタスクは、(普通は)ディスクからデータを読みとってから計算をはじめる。
「タクク数 > ディスク数」になってしまうと、並行してディスクアクセスを行なえるスレッド数(プロセス数？)の限界を越えて、
タスクノードがディスクアクセスを要求してくることになる。</p>

<p>で、ディスクアクセスが詰まってしまう。</p>
]]></content>
  </entry>
  
</feed>
